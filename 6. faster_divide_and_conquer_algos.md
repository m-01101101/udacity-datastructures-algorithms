# Divide and conquer

The name comes from the idea that the algorithm will break (or divide) the problem down into sub-problems that can be more easily solved (or conquered). Then, the solutions to these sub-problems are combined to yield an answer to the original problem. Divide and conquer algorithms are also known as recursive algorithms

## Finding the median

Finding the median an unsorted list of $n$ numbers. When $n$ is even we take the ceiling;

$$\tilde{x} = \bigg\lceil \frac{n}{2} \bigg\rceil$$

_note: $\tilde{x}$ = median_

We break this down as;

- Given an unsorted array $A$
- Finding the smallest $k^{th}$  element of $A$
- Where $1 \le k \le n$ 
- Setting $k = \frac{n}{2}$ will be the median

**Easy algorithm:** Sort the the array, take the $k^{th}$ element of the sorted list. This would be using something like `MergeSort`, taking $O(n\log(n))$

The algorithm without sorting takes $O(n)$ time and is reminiscent of `QuickSort`.

Overview of `QuickSort(A)`:

1. Choose a pivot `p`
2. Parition `A` into three parts depending on elements relation with `p`
   - $A < p$
   - $A = p$
   - $A > p$
3. Recursively sort the small elements and the big elements

The key is choosing a good pivot. Choosing the smallest or largest element will cause on the lists to be sorted to be size $n - 1$, making the run time $O(n^2)$. The median is a great pivot for `QuickSort`.

To find the median we don't have to worry about sorting the two sub-lists, rather we can recursively search the lists.

### Example

Given an array, we'll use the convention of taking the last element as the pivot and partition the starting array into three buckets, scanning through each element;

```Python
A = [5, 2, 20, 17, 11, 13, 8, 9, 11]

p = A[-1] = 11

A_le_p = [5, 2, 8, 9]

A_e_p = [11, 11]

A_ge_p = [20, 17, 13]
```

The $k^{th}$ smallest will be in one of these three lists. We can determine where the median lies depending on how large these lists are in comparison to `k`.

- If `k <= len(A_le_p)` then we want the $k^{th}$ smallest element in `A_le_p` - we do this recursively

- If `len(A_le_p) < k <= [len(A_e_p) + len(A_le_p)]` then we want the pivot `p`

- If `k > len(A_e_p)` then we want the $k^{th}$ - `[len(A_le_p) + len(A = p)]` smallest element in `A_ge_p` (k minus the number of elements discarded, the sum of the other two lists) - we do this recursively

The key is to be recursing on either the big or small list, or if lucky, just taking the `p` value.

```Python
import math

A = [5, 2, 20, 17, 11, 13, 8, 9, 11]

p = A[-1]  # 11

k = math.ceil(len(A) // 2)  # 5

A_le_p = A_e_p = A_ge_p = list()

for e in A:
    if e < p:
        A_le_p.append(e)
    elif e > p:
        A_ge_p.append(e) 
    else:
        A_e_p.append(e)

bottom_half_len = (len(A_le_p) + len(A_e_p))        

# pseudo code
if k < len(A_le_p):
    return recursive_search(A_le_p, k)
elif len(A_le_p) < k <= bottom_half_len:
    return A_e_p.pop()
elif k > bottom_half_len:
    return recursive_search(A_ge_p, k - bottom_half_len)
```

In order to achieve a run tim of $O(n)$, we need a good pivot, this will be an approximate median, a pivot that always takes off a fraction of both sides of the array.

> In computer science, the median of medians is an approximate (median) selection algorithm, frequently used to supply a good pivot for an exact selection algorithm, mainly the quickselect, that selects the kth largest element of an initially unsorted array.
>
> When this approximate median is used as an improved pivot, the worst-case complexity of quickselect reduces significantly from quadratic to linear

We need a constant that is less than 1. If the median is $\frac{1}{2}$, $\frac{3}{4}$ is still a good pivot, so is $\frac{99}{100}$.

<img src=md_refs/d_and_c1.png><br>

If we only need to find a pivot as good as $\frac{3}{4}$ (0.75), we have a slack of 0.24 (keeping us under a constant of 1). We can use this slack to dedicate to ensuring we find a good pivot.

We use the slack (of 0.2) by taking a subset of `A` where $|S| = \frac{n}{5}$. We recursively run our median algorithm on this subset, we set `p` to the median of the subset.

<img src=md_refs/d_and_c2.png><br>

We need to choose the subset S so what that it is a good representation of the entire pivot.

__Algorithm__;

(1) We split our array `A` into $\frac{n}{5}$ groups, of five elements each and pick one representative from each group.

(2) We'll pick the median from each array, each group is only five element so is trivial to sort, $m_i = median (G_i)$

(3) Our subset of `A` is the collection of these medians, $S = [m_1, m_2, ..., m_{\frac{n}{5}}]$

(4) We find our pivot `p` but calling the recursive divide and conquer algorithm on our subset `S`, so that; `p = FastSelect(S, n/10)`. `S` has five elements, so to find the median we need $k = \frac{n}{10}$

(5) We partition the original set `A` using our pivot, into three groups;

- `A < p`
- `A == p`
- `A > p`

(6) Based on the sizes of these three sets we know which set to recursively search on to find the median.

- If the size of the small set is equal to, or larger, than $k$, then we recurse on that
  - $k \leq |A < p|$
    - _note, two lines denotes the size of the array_
  - Then
  - `p = FastSelect(A<p, k)`
- If $k$ is greater than the size of the small set plus the middle set then we know $k$ lies in the big set (big as in bigger than our pivot)
  - $k > ( |A < p | + |A == p| )$
  - Don't forget, when running the Fast Select divide and conquer algorithm we must alter $k$ to be the median of this array
  - `p = FastSelect(A>p, k - (|A < p| + |A == p|))`
  - Else return `p`

### Run time

Our run time of the algorithm is made up of;

- Breaking the array into five groups: $O(n)$
- Sorting the groups and getting the median: $\frac{O(1)}{group}$
- Run the algorithm on subset `S`: $T(\frac{n}{5})$
- Run the algorithm on one of three subsets we've divided `A` in relation to our pivot from `S`: $T(\frac{3}{4}n)$, this is guareented to an extent because we know we've used a good pivot.

$$T(n) = O(n) + T(\frac{n}{5}) + T(\frac{3}{4}n) = O(n)$$

The important element is using a fraction, rather than a constant

$$ \frac{3}{4} + \frac{1}{5} < 1$$

```Python
def fastSelect(Arr: List[int], k: int):  # k is an index
    n = len(Arr)  # length of the original array
    
    if (k > 0 and k <= n):  # k should be a valid index         
        # Helper variables
        setOfMedians = []
        Arr_Less_P = []
        Arr_Equal_P = []
        Arr_More_P = []
        i = 0
        
        # Step 1 - Break Arr into groups of size 5
        # Step 2 - For each group, sort and find median (middle). Add the median to setOfMedians
        while (i < n // 5):                     # n//5 gives the integer quotient of the division 
            median = findMedian(Arr, 5*i, 5)    # find median of each group of size 5
            setOfMedians.append(median)         
            i += 1

        # If n is not a multiple of 5, then a last group with size = n % 5 will be formed
        if (5*i < n): 
            median = findMedian(Arr, 5*i, n % 5)
            setOfMedians.append(median)
        
        # Step 3 - Find the median of setOfMedians
        if (len(setOfMedians) == 1):            # Base case for this task
            pivot = setOfMedians[0]
        elif (len(setOfMedians)>1):
            pivot = fastSelect(setOfMedians, (len(setOfMedians)//2))
        
        # Step 4 - Partition the original Arr into three sub-arrays
        for element in Arr:
            if (element<pivot):
                Arr_Less_P.append(element)
            elif (element>pivot):
                Arr_More_P.append(element)
            else:
                Arr_Equal_P.append(element)
        
        # Step 5 - Recurse based on the sizes of the three sub-arrays
        if (k <= len(Arr_Less_P)):
            return fastSelect(Arr_Less_P, k)
        
        elif (k > (len(Arr_Less_P) + len(Arr_Equal_P))):
            return fastSelect(Arr_More_P, (k - len(Arr_Less_P) - len(Arr_Equal_P)))
            
        else:
            return pivot     

# Helper function
def findMedian(Arr, start, size): 
    myList = [] 
    for i in range(start, start + size): 
        myList.append(Arr[i]) 
          
    # Sort the array  
    myList.sort() 
  
    # Return the middle element 
    return myList[size // 2] 
```

## Max sub-array

You are given an array `arr` having `n` integers. You have to find the maximum sum of contiguous subarray among all the possible subarrays. This problem is commonly called as [Maximum Subarray Problem](https://en.wikipedia.org/wiki/Maximum_subarray_problem). 

Solving this problem in *O(nlogn)* time, using Divide and Conquer approach;

**Example 1**<br>
Input: `arr = [-2, 1, -3, 5, 0, 3, 2, -5, 4]`<br>
Output: `Maximum Sum = 10` for the  `subarray = [5, 0, 3, 2]`<br>

**Example 2**<br>
Input: `arr = [-2, -5, 6, -2, -3, 1, 5, -6]`<br>
Output: `Maximum Sum = 7`  for the  `subarray = [6, -2, -3, 1, 5]`<br>

### Approach

(1) Divide the given array into three subarray w.r.t. the middle, say Left, Right, and Cross subarrays.

(2) Recurse on the Left part, and Right part untill you reach the base condition, i.e. single element in a subarray.

(3) Calculate the maximum sum of the Left, Right, and Cross subarrays, say `L`, `R`, and `C` respectively. **Return the maximum of `L`, `R`, and `C`.

__Calculating C__, 

- Start from the middle index, and traverse (sum the elements) in the left direction. Keep track of the maximum sum on the left part, say `leftMaxSum`.
- Similarly, start from the (middle +1) index, and traverse (sum the elements) in the right direction.  Keep track of the maximum sum on the right part, say `rightMaxSum`.
- Return the `(leftMaxSum + rightMaxSum)`, as `C`.

<img src=md_refs/d_and_c3.png><br>

### Run time

<img src=md_refs/d_and_c4.png><br>

### Implementation

```Python
'''Helper Function - Find the max crossing sum w.r.t. middle index'''
def maxCrossingSum(arr: List[int], start: int, mid: int,  stop: int):
    
    leftSum = arr[mid]  # start point
    leftMaxSum = arr[mid]  # Keep track of maximum sum
    # Traverse in reverse direction from (mid-1) to start 
    for i in range(mid-1, start-1, -1):
        leftSum = leftSum + arr[i]
        if (leftSum > leftMaxSum):
            leftMaxSum = leftSum
    
    rightSum = arr[mid+1]  # start point
    rightMaxSum = arr[mid+1]  # keep track of maximum sum
    # Traverse in forward direction from (mid+2) to stop
    for j in range(mid+2, stop+1):
        rightSum = rightSum + arr[j]
        if (rightSum > rightMaxSum):
            rightMaxSum = rightSum

    return (rightMaxSum + leftMaxSum)


def maxSubArrayRecursive(arr, start, stop):
    '''Recursive function'''    
    # Base case
    if (start==stop):
        return arr[start]

    if(start < stop):
        mid = (start+stop)//2  # Get the middle index
        L = maxSubArrayRecursive(arr, start, mid)  # Recurse on the Left part
        R = maxSubArrayRecursive(arr, mid+1, stop)  # Recurse on the Right part
        C = maxCrossingSum(arr, start, mid, stop)  # Find the max crossing sum w.r.t. middle index
        return max(C, max(L,R))  # Return the maximum of (L,R,C)
    
    else:  # If ever start > stop. Not feasible. 
        return nums[start]

def maxSubArray(arr):
    start = 0  # staring index of original array
    stop = len(arr) -1  # ending index of original array
    return maxSubArrayRecursive(arr, start, stop)
```

## Note

Quicksort and Mergesort are a few examples that follow the Divide and Conquer approach. There are a few points to note while deciding if one should go for faster Divide and Conquer approach:

1. The problem should be on a bigger scale.
2. The sub-problem must look precisely similar to the original problem in hand.
3. Use recursion to solve the problem. It means that the solution will be built for the smallest sub-problem (base case) first.
4. There is a trade-off between memory usage and speed of execution. Recursion comes with a price of extra memory usage for executing the call stack. But, if you use multi-threading, you can compute the solution even much faster.
5. In case if many sub-problems look precisely the same, then we don't want to re-execute the same again and again. In such cases, you can consider storing the results of the execution, and thus reuse them whenever required. This strategy is called Memoization (in Dynamic Programming approach).
